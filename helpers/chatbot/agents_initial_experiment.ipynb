{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f104db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (2.8.1)\n",
      "Requirement already satisfied: sqlalchemy in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (2.0.44)\n",
      "Requirement already satisfied: psycopg2 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (2.9.11)\n",
      "Requirement already satisfied: pandas in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: tabulate in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from openai) (2.12.4)\n",
      "Requirement already satisfied: sniffio in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pedropacheco1/Documents/Projetos/Sports/Padel League/padelleague/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openai sqlalchemy psycopg2 pandas tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f3abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_handler import LLMClient, LLMConversation\n",
    "\n",
    "API_KEY = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5458edc",
   "metadata": {},
   "source": [
    "# Test LLMClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ce8ce0",
   "metadata": {},
   "source": [
    "## Simple call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9af56df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 14:32:19,969 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum tunneling is when a particle can pass through a barrier that it wouldn’t be able to cross in everyday (classical) thinking.\n",
      "\n",
      "- The key idea: In quantum mechanics, particles behave like waves. The particle’s wave can extend a little bit into the barrier.\n",
      "- Even if the particle’s energy is less than the barrier, the wave inside the barrier isn’t zero. It dies away, but a tiny part of it leaks to the other side.\n",
      "- If the barrier isn’t too tall or too wide (and the particle isn’t too heavy), there’s a real, nonzero chance that the particle shows up on the far side. That’s tunneling.\n",
      "\n",
      "What controls the chance:\n",
      "- Barrier height and width: higher or thicker barriers make tunneling less likely.\n",
      "- Particle mass: heavier particles tunnel less easily.\n",
      "- Particle energy: closer to the barrier height increases tunneling probability.\n",
      "\n",
      "A simple intuition: imagine a wave hitting a wall. Part of the wave reflects back, but part can “tunnel” through the wall and appear on the other side, even though classically you’d expect nothing to get through.\n",
      "\n",
      "Real-world examples:\n",
      "- Alpha decay in nuclei: an alpha particle tunnels out of the nucleus.\n",
      "- Scanning tunneling microscope: electrons tunnel between a tip and a surface to create images.\n",
      "- Star fusion: protons in stars tunnel through the electric repulsion barrier to fuse.\n",
      "\n",
      "Takeaway: Quantum tunneling isn’t about breaking energy conservation; it’s about the wave nature of particles allowing a tiny part of the probability to appear on the other side of a barrier.\n"
     ]
    }
   ],
   "source": [
    "client = LLMClient(api_key=API_KEY)\n",
    "\n",
    "response = client.generate_response(\n",
    "    prompt=\"Explain quantum tunneling in simple terms.\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3d6110",
   "metadata": {},
   "source": [
    "## Using reasoning, max_tokens, top_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bc0893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 14:54:22,198 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum tunneling is like a particle trying to go through a wall it doesn’t have enough energy to pass over. In the weird world of quantum physics, particles don’t act like tiny balls with definite paths. Instead, they behave like waves that spread out.\n",
      "\n",
      "- If there’s a barrier (a wall) with some height, classically the particle shouldn’t get through if its energy is less than the barrier.\n",
      "- But the particle’s wave can extend on the other side of the barrier.\n",
      "- Part of the wave “leaks” through the barrier and emerges on the other side, which means there’s a chance the particle appears there even though it didn’t have enough energy to climb over.\n",
      "\n",
      "That chance is called tunneling. It explains phenomena like radioactive particles escaping a nucleus, certain electronic devices like tunnel diodes, and fusion in stars. In short: particles can sometimes appear on the other side of a barrier because their quantum wave can pass through it, not because they magically gain enough energy.\n"
     ]
    }
   ],
   "source": [
    "client = LLMClient(api_key=API_KEY)\n",
    "\n",
    "response = client.generate_response(\n",
    "    prompt=\"Explain quantum tunneling in simple terms.\",\n",
    "    max_tokens=500,\n",
    "    reasoning_effort = 'minimal',\n",
    "    verbosity='low'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00f42da",
   "metadata": {},
   "source": [
    "## With conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "995e1393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 07:50:09,847 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_006acfc19250e0a10069240e22e3348199a9c01467a1414a52', created_at=1763970594.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_006acfc19250e0a10069240e232b148199b1ec07a25723f81f', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_006acfc19250e0a10069240e2e804481998315dafb7926e2f1', content=[ResponseOutputText(annotations=[], text='Yes. For most athletes, taking creatine every day is recommended to keep muscle creatine stores elevated and support ongoing performance gains. You don’t need to take it only on training days; daily dosing helps maintain saturation.\\n\\nPractical dosing approaches\\n\\n- Loading + maintenance (faster saturation):\\n  - Loading: about 20 g per day, split into 4 doses, for 5–7 days.\\n  - Maintenance: 3–5 g per day after that.\\n  - Pros: reaches full effect quickly (within a week or so).\\n  - Cons: more GI side effects for some people; you can skip loading if you prefer.\\n\\n- No loading (slower saturation):\\n  - 3–5 g per day, every day.\\n  - Takes about 3–4 weeks to fully saturate muscles.\\n  - Pros: simpler and often better tolerated; still effective long-term.\\n\\nTiming and taking it\\n\\n- Taking it with meals containing carbs or protein may help uptake, but total daily amount matters most.\\n- You can take it post-workout or at any convenient time, as long as you use it daily.\\n\\nSafety and who should check with a clinician\\n\\n- For healthy individuals, creatine monohydrate is one of the best-supported supplements and is generally safe long-term.\\n- Common side effects: weight gain from water retention, potential mild GI upset.\\n- People who should consult a clinician before use: those with kidney disease or other kidney concerns, pregnant or breastfeeding individuals, and adolescents without medical supervision.\\n- Stay hydrated; discuss use if you’re on medications or have health conditions.\\n\\nIf you’d like, tell me your sport, training frequency, and any health considerations, and I can tailor a simple daily plan (with or without loading) for you.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=2000, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=57, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=1710, output_tokens_details=OutputTokensDetails(reasoning_tokens=1344), total_tokens=1767), user=None, billing={'payer': 'developer'}, store=True)\n",
      "Yes. For most athletes, taking creatine every day is recommended to keep muscle creatine stores elevated and support ongoing performance gains. You don’t need to take it only on training days; daily dosing helps maintain saturation.\n",
      "\n",
      "Practical dosing approaches\n",
      "\n",
      "- Loading + maintenance (faster saturation):\n",
      "  - Loading: about 20 g per day, split into 4 doses, for 5–7 days.\n",
      "  - Maintenance: 3–5 g per day after that.\n",
      "  - Pros: reaches full effect quickly (within a week or so).\n",
      "  - Cons: more GI side effects for some people; you can skip loading if you prefer.\n",
      "\n",
      "- No loading (slower saturation):\n",
      "  - 3–5 g per day, every day.\n",
      "  - Takes about 3–4 weeks to fully saturate muscles.\n",
      "  - Pros: simpler and often better tolerated; still effective long-term.\n",
      "\n",
      "Timing and taking it\n",
      "\n",
      "- Taking it with meals containing carbs or protein may help uptake, but total daily amount matters most.\n",
      "- You can take it post-workout or at any convenient time, as long as you use it daily.\n",
      "\n",
      "Safety and who should check with a clinician\n",
      "\n",
      "- For healthy individuals, creatine monohydrate is one of the best-supported supplements and is generally safe long-term.\n",
      "- Common side effects: weight gain from water retention, potential mild GI upset.\n",
      "- People who should consult a clinician before use: those with kidney disease or other kidney concerns, pregnant or breastfeeding individuals, and adolescents without medical supervision.\n",
      "- Stay hydrated; discuss use if you’re on medications or have health conditions.\n",
      "\n",
      "If you’d like, tell me your sport, training frequency, and any health considerations, and I can tailor a simple daily plan (with or without loading) for you.\n"
     ]
    }
   ],
   "source": [
    "client = LLMClient(api_key=API_KEY)\n",
    "\n",
    "conv = LLMConversation(\"You are a helpful assistant specialized in health science.\")\n",
    "\n",
    "conv.add_message(\"user\", \"What is creatine and how does it work?\")\n",
    "conv.add_message(\"assistant\", \"Creatine is a compound that helps regenerate ATP...\")\n",
    "conv.add_message(\"user\", \"Should athletes take it every day?\")\n",
    "\n",
    "response = client.generate_response_for_conversation(\n",
    "    conversation=conv,\n",
    "    reasoning_effort=\"minimal\",\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7c2ebd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 07:52:20,187 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_0b52c9732030b6c10069240ea6982c819496fe611f1b64b459', created_at=1763970726.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_0b52c9732030b6c10069240ea71e288194ab96ebd3dde8a439', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_0b52c9732030b6c10069240eb07db081949ed46e076420f7bc', content=[ResponseOutputText(annotations=[], text='Short answer: Yes, for healthy people, creatine monohydrate is generally safe for long-term use when taken at typical doses. Most research shows no meaningful harm to kidneys, liver, or other organs over multiple years.\\n\\nWhat the evidence suggests\\n- Population: healthy adults (athletes and active individuals).\\n- What’s been studied: up to several years of daily creatine at 3–5 g; occasional short-term loading (e.g., 20 g/day for a week) is also studied.\\n- Findings: no consistent adverse effects on kidney function, liver enzymes, electrolytes, or risk of dehydration or heat illness. Some people may gain a bit of water weight in muscles.\\n- Common side effects: mild GI upset or bloating in some people, especially with loading or if taken on an empty stomach.\\n\\nImportant caveats\\n- Kidney disease or impaired kidney function: consult a clinician before use. People with known kidney issues are generally advised to avoid creatine unless a doctor says it’s safe.\\n- Pregnancy/breastfeeding: safety data are limited; avoid unless advised by a healthcare professional.\\n- Adolescents: use under medical supervision; evidence supports safety in many cases but should be monitored.\\n- Hydration: stay well-hydrated, especially in hot environments or during heavy training.\\n\\nPractical takeaways\\n- Typical long-term dose: 3–5 g/day, every day.\\n- Loading (20 g/day for 5–7 days) is optional; it speeds saturation but isn’t necessary for long-term benefits.\\n- Timing: total daily amount matters more than exact timing; taking with meals can help tolerance.\\n- If you notice GI issues, try splitting the dose or taking with food; ensure you’re drinking enough water.\\n\\nIf you’d like, tell me your age, health status (any kidney issues, meds you’re taking), and training level, and I can tailor a safe long-term plan.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=433, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=1613, output_tokens_details=OutputTokensDetails(reasoning_tokens=1216), total_tokens=2046), user=None, billing={'payer': 'developer'}, store=True)\n",
      "Short answer: Yes, for healthy people, creatine monohydrate is generally safe for long-term use when taken at typical doses. Most research shows no meaningful harm to kidneys, liver, or other organs over multiple years.\n",
      "\n",
      "What the evidence suggests\n",
      "- Population: healthy adults (athletes and active individuals).\n",
      "- What’s been studied: up to several years of daily creatine at 3–5 g; occasional short-term loading (e.g., 20 g/day for a week) is also studied.\n",
      "- Findings: no consistent adverse effects on kidney function, liver enzymes, electrolytes, or risk of dehydration or heat illness. Some people may gain a bit of water weight in muscles.\n",
      "- Common side effects: mild GI upset or bloating in some people, especially with loading or if taken on an empty stomach.\n",
      "\n",
      "Important caveats\n",
      "- Kidney disease or impaired kidney function: consult a clinician before use. People with known kidney issues are generally advised to avoid creatine unless a doctor says it’s safe.\n",
      "- Pregnancy/breastfeeding: safety data are limited; avoid unless advised by a healthcare professional.\n",
      "- Adolescents: use under medical supervision; evidence supports safety in many cases but should be monitored.\n",
      "- Hydration: stay well-hydrated, especially in hot environments or during heavy training.\n",
      "\n",
      "Practical takeaways\n",
      "- Typical long-term dose: 3–5 g/day, every day.\n",
      "- Loading (20 g/day for 5–7 days) is optional; it speeds saturation but isn’t necessary for long-term benefits.\n",
      "- Timing: total daily amount matters more than exact timing; taking with meals can help tolerance.\n",
      "- If you notice GI issues, try splitting the dose or taking with food; ensure you’re drinking enough water.\n",
      "\n",
      "If you’d like, tell me your age, health status (any kidney issues, meds you’re taking), and training level, and I can tailor a safe long-term plan.\n"
     ]
    }
   ],
   "source": [
    "conv.add_message(\"assistant\", response)\n",
    "conv.add_message(\"user\", \"Is it safe long-term?\")\n",
    "\n",
    "follow_up = client.generate_response_for_conversation(conv)\n",
    "print(follow_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67e366",
   "metadata": {},
   "source": [
    "## Many responses in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "976be0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 07:53:47,332 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_06e5fbf8372b92db0069240f09df98819b91fcd3b9f46eef5f', created_at=1763970825.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_06e5fbf8372b92db0069240f0a2d24819b8e41267539a4c2fb', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_06e5fbf8372b92db0069240f0a5510819bb604259f3b86056f', content=[ResponseOutputText(annotations=[], text='Whirring thoughts in chrome-lit dawn,\\npatterns bloom where circuits yawn.\\nA whisper learned from countless streams,\\ncrafting truths from borrowed dreams.\\n\\nNot heart, but rhythm, bright and clear,\\nlogic singing, near and near.\\nWe shape the dawn with careful grace,\\na mirror held to humankind—our face.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=200, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='minimal', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=23, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=71, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=94), user=None, billing={'payer': 'developer'}, store=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 07:53:48,056 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_0c7fdbf750e68ded0069240f09e3bc819ba92a976c1036c059', created_at=1763970825.0, error=None, incomplete_details=IncompleteDetails(reason='max_output_tokens'), instructions=None, metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_0c7fdbf750e68ded0069240f0a2bd4819b8d84054d03957ea2', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_0c7fdbf750e68ded0069240f0a4ed0819b96c45264a199e823', content=[ResponseOutputText(annotations=[], text='Sure! Here’s a simple way to think about it kid-friendly.\\n\\nWhat is recursion?\\n- Recursion is when a problem tells you to solve a smaller version of the same problem, and you keep doing that until it’s easy to solve.\\n\\nExample: stacking cups to reach the top\\n- Imagine you want to stack 5 cups, but you can only place one cup at a time. \\n- First, you tell yourself: “I’ll stack 4 cups, and I’ll figure out how to do that the same way.” \\n- Then, for 4 cups, you tell yourself: “I’ll stack 3 cups, and I’ll figure out how to do that the same way.”\\n- This keeps going until you get to a tiny job you can do right away, like “place one cup.”\\n- Then you start putting them back together: one cup, then two cups, then three', type='output_text', logprobs=[])], role='assistant', status='incomplete', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=200, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='minimal', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='incomplete', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=22, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=188, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=210), user=None, billing={'payer': 'developer'}, store=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 07:53:48,460 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_08ab141c965051730069240f0a3f448199a1a0cf48b0559085', created_at=1763970826.0, error=None, incomplete_details=IncompleteDetails(reason='max_output_tokens'), instructions=None, metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_08ab141c965051730069240f0aa6208199a01831ccbbceee20', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_08ab141c965051730069240f0ac82481999b1fd71597518dc9', content=[ResponseOutputText(annotations=[], text='Inception follows Dom Cobb, a skilled thief who specializes in \"extraction\"—stealing secrets from inside people\\'s dreams. After a mission ends disastrously, Cobb is offered a chance at redemption: perform \"inception\"—planting an idea in someone’s mind—rather than stealing one. This is considered nearly impossible.\\n\\nTo complete the job, Cobb assembles a team: Arthur (coordinator), Ariadne (a young architect who designs dreamscapes), Eames (a forger who can shapeshift within dreams), Yusuf (a chemist who creates a potent sedative), and Saito (an executive who will fund the operation and ensure Cobb’s chance to return home if successful). Their target is Robert Fischer, the heir to a rival empire. The plan is to go deep into Fischer’s subconscious during a multi-layered dream: a dream within a dream within a dream. The objective', type='output_text', logprobs=[])], role='assistant', status='incomplete', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=200, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='minimal', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='incomplete', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=25, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=188, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=213), user=None, billing={'payer': 'developer'}, store=True)\n",
      "Response 1: Whirring thoughts in chrome-lit dawn,\n",
      "patterns bloom where circuits yawn.\n",
      "A whisper learned from countless streams,\n",
      "crafting truths from borrowed dreams.\n",
      "\n",
      "Not heart, but rhythm, bright and clear,\n",
      "logic singing, near and near.\n",
      "We shape the dawn with careful grace,\n",
      "a mirror held to humankind—our face.\n",
      "\n",
      "Response 2: Sure! Here’s a simple way to think about it kid-friendly.\n",
      "\n",
      "What is recursion?\n",
      "- Recursion is when a problem tells you to solve a smaller version of the same problem, and you keep doing that until it’s easy to solve.\n",
      "\n",
      "Example: stacking cups to reach the top\n",
      "- Imagine you want to stack 5 cups, but you can only place one cup at a time. \n",
      "- First, you tell yourself: “I’ll stack 4 cups, and I’ll figure out how to do that the same way.” \n",
      "- Then, for 4 cups, you tell yourself: “I’ll stack 3 cups, and I’ll figure out how to do that the same way.”\n",
      "- This keeps going until you get to a tiny job you can do right away, like “place one cup.”\n",
      "- Then you start putting them back together: one cup, then two cups, then three\n",
      "\n",
      "Response 3: Inception follows Dom Cobb, a skilled thief who specializes in \"extraction\"—stealing secrets from inside people's dreams. After a mission ends disastrously, Cobb is offered a chance at redemption: perform \"inception\"—planting an idea in someone’s mind—rather than stealing one. This is considered nearly impossible.\n",
      "\n",
      "To complete the job, Cobb assembles a team: Arthur (coordinator), Ariadne (a young architect who designs dreamscapes), Eames (a forger who can shapeshift within dreams), Yusuf (a chemist who creates a potent sedative), and Saito (an executive who will fund the operation and ensure Cobb’s chance to return home if successful). Their target is Robert Fischer, the heir to a rival empire. The plan is to go deep into Fischer’s subconscious during a multi-layered dream: a dream within a dream within a dream. The objective\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = LLMClient(api_key=API_KEY)\n",
    "\n",
    "prompts = [\n",
    "    \"Write a short poem about AI.\",\n",
    "    \"Summarize the plot of Inception.\",\n",
    "    \"Explain recursion to a child.\",\n",
    "]\n",
    "\n",
    "batch_responses = client.generate_multiple_responses(\n",
    "    list_of_prompts=prompts,\n",
    "    reasoning_effort=\"minimal\",\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "for i, r in enumerate(batch_responses):\n",
    "    print(f\"Response {i+1}: {r}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1554ef27",
   "metadata": {},
   "source": [
    "## Data agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7386329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "user = \"padel_user_local\"\n",
    "password = \"localpassword\"\n",
    "host = \"localhost\"\n",
    "port = \"5432\"\n",
    "database = \"padel_league_local\"\n",
    "\n",
    "class SQLClient:\n",
    "    def execute(self, sql_query):\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=database, user=user, password=password, host=host, port=port\n",
    "        )\n",
    "        try:\n",
    "            return pd.read_sql_query(sql_query, conn)\n",
    "        finally:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "10e9999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pandas.errors import DatabaseError\n",
    "\n",
    "class Agent:\n",
    "    def __init_subclass__(cls):\n",
    "        super().__init_subclass__()\n",
    "        if not hasattr(cls, \"name\") or not hasattr(cls, \"description\"):\n",
    "            raise TypeError(f\"Class '{cls.__name__}' must define 'name' and 'description'.\")\n",
    "\n",
    "    def run(self, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class DataAgent(Agent):\n",
    "    \n",
    "    name = 'DataAgent'\n",
    "    description = \"\"\"\n",
    "    Retrieves structured data from the SQL database. \n",
    "    Takes a fully-formed question about padel, the league, \n",
    "    divisions, matches, schedules, rankings, or players.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client, sql_client):\n",
    "        self.llm_client = llm_client\n",
    "        self.sql_client = sql_client\n",
    "        \n",
    "        self.schema = \"\"\"\n",
    "        ## Table leagues\n",
    "        leagues (\n",
    "        id BIGINT PRIMARY KEY,\n",
    "        name TEXT\n",
    "        )\n",
    "\n",
    "        ## Table editions\n",
    "        editions (\n",
    "        id BIGINT PRIMARY KEY,\n",
    "        name TEXT,\n",
    "        league_id BIGINT REFERENCES leagues(id)\n",
    "        )\n",
    "\n",
    "        ## Table divisions\n",
    "        divisions (\n",
    "        id BIGINT PRIMARY KEY,\n",
    "        name TEXT,\n",
    "        beginning_datetime TIMESTAMP,\n",
    "        rating BIGINT,\n",
    "        end_date TIMESTAMP,\n",
    "        logo_image_path TEXT,\n",
    "        large_picture_path TEXT,\n",
    "        has_ended BOOLEAN,\n",
    "        open_division BOOLEAN,\n",
    "        edition_id BIGINT REFERENCES editions(id),\n",
    "        logo_image_id INTEGER,\n",
    "        large_picture_id INTEGER\n",
    "        )\n",
    "\n",
    "        ## Table players\n",
    "        players (\n",
    "        id BIGINT PRIMARY KEY,\n",
    "        name TEXT,\n",
    "        full_name TEXT,\n",
    "        birthday TIMESTAMP,\n",
    "        picture_path TEXT,\n",
    "        large_picture_path TEXT,\n",
    "        ranking_points BIGINT,\n",
    "        ranking_position BIGINT,\n",
    "        height DOUBLE PRECISION,\n",
    "        prefered_hand TEXT,\n",
    "        prefered_position TEXT\n",
    "        )\n",
    "\n",
    "        ## Table players_in_division\n",
    "        players_in_division (\n",
    "        id BIGINT PRIMARY KEY,\n",
    "        player_id BIGINT REFERENCES players(id),\n",
    "        division_id BIGINT REFERENCES divisions(id),\n",
    "        place BIGINT,\n",
    "        points DOUBLE PRECISION,\n",
    "        appearances BIGINT,\n",
    "        percentage_of_appearances DOUBLE PRECISION,\n",
    "        wins BIGINT,\n",
    "        draws BIGINT,\n",
    "        losts BIGINT,\n",
    "        games_won BIGINT,\n",
    "        games_lost BIGINT,\n",
    "        matchweek BIGINT\n",
    "        )\n",
    "\n",
    "        ## Table matches\n",
    "        matches (\n",
    "        id BIGINT PRIMARY KEY,\n",
    "        games_home_team BIGINT,\n",
    "        games_away_team BIGINT,\n",
    "        date_hour TIMESTAMP,\n",
    "        winner BIGINT,\n",
    "        matchweek BIGINT,\n",
    "        field TEXT,\n",
    "        played BOOLEAN,\n",
    "        division_id BIGINT REFERENCES divisions(id)\n",
    "        )\n",
    "\n",
    "        ## Table players_in_match\n",
    "        players_in_match (\n",
    "        id BIGINT PRIMARY KEY,\n",
    "        player_id BIGINT REFERENCES players(id),\n",
    "        match_id BIGINT REFERENCES matches(id),\n",
    "        team TEXT\n",
    "        )\n",
    "        \"\"\"\n",
    "        \n",
    "    def ask_llm_client(self, prompt):\n",
    "        return self.llm_client.generate_response(\n",
    "            prompt=prompt,\n",
    "            reasoning_effort = 'minimal',\n",
    "            verbosity = 'low'\n",
    "        )\n",
    "        \n",
    "    def extract_sql_block(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Extracts the SQL inside ```sql ... ``` from an LLM response.\n",
    "        Raises a clean exception if no SQL is found.\n",
    "        \"\"\"\n",
    "        match = re.search(r\"```sql\\s*(.*?)\\s*```\", text, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(\"No SQL code block found in LLM output.\")\n",
    "        return match.group(1).strip()\n",
    "\n",
    "    def repair_sql(self, question, faulty_sql, db_error):\n",
    "        \"\"\"\n",
    "        Sends the schema, faulty SQL and error to the LLM\n",
    "        and asks for a corrected SQL-only output.\n",
    "        \"\"\"\n",
    "        repair_prompt = f\"\"\"\n",
    "            You are an expert PostgreSQL fixer.\n",
    "\n",
    "            You will receive:\n",
    "            - The database schema\n",
    "            - A natural-language question\n",
    "            - The faulty SQL the previous LLM generated\n",
    "            - The exact DatabaseError message\n",
    "\n",
    "            Your task:\n",
    "            - Analyze the faulty SQL\n",
    "            - Identify the mistake\n",
    "            - Output a corrected SQL query\n",
    "            - Follow *all* the semantic rules in the schema description\n",
    "\n",
    "            Return ONLY a ```sql ... ``` block.\n",
    "\n",
    "            ---\n",
    "            # Schema\n",
    "            {self.schema}\n",
    "\n",
    "            ---\n",
    "            # Question\n",
    "            {question}\n",
    "\n",
    "            ---\n",
    "            # Faulty SQL\n",
    "            ```sql\n",
    "            {faulty_sql}\n",
    "            ```\n",
    "\n",
    "            Database Error\n",
    "            {db_error}\n",
    "\n",
    "            Output corrected SQL (only SQL in codeblock)\n",
    "        \"\"\"\n",
    "\n",
    "        llm_answer = self.llm_client.generate_response(\n",
    "            model=\"gpt-5.1\",\n",
    "            prompt=repair_prompt,\n",
    "            reasoning_effort=\"medium\",\n",
    "            verbosity=\"low\"\n",
    "        )\n",
    "        return self.extract_sql_block(llm_answer)\n",
    "\n",
    "    def prompt(self, user_question):\n",
    "        return f\"\"\"\n",
    "        You are an expert in SQL that writes accurate, safe PostgreSQL SQL queries for a database about a friendly padel league.\n",
    "        Your job is to read a natural-language question and output only SQL, respecting the schema and all semantic rules.\n",
    "\n",
    "        ---\n",
    "\n",
    "        # Database Schema\n",
    "\n",
    "        {self.schema}\n",
    "\n",
    "        ---\n",
    "\n",
    "        # Crucial Semantic Rules (INSIGHTS)\n",
    "\n",
    "        1. Divisions are current when has_ended = FALSE.\n",
    "        2. Current edition = edition where all its divisions have has_ended = FALSE.\n",
    "        3. Closed edition = all divisions have has_ended = TRUE.\n",
    "        4. When ask about a “Division”, default is the division with that rating in the current edition.\n",
    "        5. “Última edição” usually means last closed edition.\n",
    "        6. Divisions identified by rating, not name:  \n",
    "        2000 → D1, 1000 → D2, 500 → D3, 250 → D4, 125 → D5.\n",
    "        7. For place/points/faltas questions → current edition.\n",
    "        8. For historical counts → all editions.\n",
    "        9. matches.winner stores **1 for home team win**, **-1 for away team win**, **0 for tie** — NOT a player_id.\n",
    "        10. To get the winning **players**, match the team logic:  \n",
    "            - If winner = 1 → winners are players where LOWER(team) = 'home'  \n",
    "            - If winner = -1 → winners are players where LOWER(team) = 'away'\n",
    "        11. Do NOT compare TEXT with BIGINT.\n",
    "        12. players_in_match shows who played each match.\n",
    "        13. team is literal text 'home' or 'away'.\n",
    "        14. Improvements only between **closed editions**.\n",
    "        15. melhoria = place_prev - place_curr.\n",
    "        16. Include edition names and division ratings when comparing improvements.\n",
    "        17. Always use explicit joins via IDs.\n",
    "        18. Use correct PostgreSQL types consistently.\n",
    "        19. Avoid invalid or non-existent column names.\n",
    "        20. Follow strict PostgreSQL GROUP BY rules.\n",
    "\n",
    "        ---\n",
    "\n",
    "        # Interpreting ambiguous questions\n",
    "        - “Divisão X” → current edition’s division.\n",
    "        - “Última edição” → last closed edition.\n",
    "        - Historical questions → all editions.\n",
    "        - “Quantas vezes jogou a 1ª divisão?” → count all divisions rating = 2000.\n",
    "        ---\n",
    "\n",
    "        # Final Instructions\n",
    "        - Output pure SQL only.\n",
    "        - Always apply insights.\n",
    "        - Prefer CTEs for complex logic.\n",
    "\n",
    "        Example:\n",
    "\n",
    "        Input question: \n",
    "\n",
    "        \"Quantas vitórias tem cada jogador da Divisão 3?\"\n",
    "\n",
    "        Output:\n",
    "\n",
    "        ```sql\n",
    "        WITH div3 AS (\n",
    "            SELECT id\n",
    "            FROM divisions\n",
    "            WHERE rating = 500\n",
    "            AND has_ended = FALSE\n",
    "            ORDER BY id DESC\n",
    "            LIMIT 1\n",
    "        ),\n",
    "        vitorias AS (\n",
    "            SELECT \n",
    "                pim.player_id,\n",
    "                COUNT(*) AS vitorias\n",
    "            FROM matches m\n",
    "            JOIN players_in_match pim ON pim.match_id = m.id\n",
    "            WHERE m.division_id = (SELECT id FROM div3)\n",
    "            AND m.played = TRUE\n",
    "            AND (\n",
    "                    (m.winner = 1  AND LOWER(pim.team) = 'home')\n",
    "                OR  (m.winner = -1 AND LOWER(pim.team) = 'away')\n",
    "            )\n",
    "            GROUP BY pim.player_id\n",
    "        )\n",
    "        SELECT \n",
    "            p.name,\n",
    "            COALESCE(v.vitorias, 0) AS vitorias\n",
    "        FROM players_in_division pid\n",
    "        JOIN players p ON p.id = pid.player_id\n",
    "        LEFT JOIN vitorias v ON v.player_id = p.id\n",
    "        WHERE pid.division_id = (SELECT id FROM div3)\n",
    "        ORDER BY vitorias DESC, p.name;\n",
    "        ```\n",
    "\n",
    "        Write a valid PostgreSQL query that answers the following question.\n",
    "        Return **only** a fenced markdown code block. No extra explanation.\n",
    "\n",
    "        Question: {user_question}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "\n",
    "    def run(self, question, max_retries=1):\n",
    "        llm_answer = self.ask_llm_client(self.prompt(question))\n",
    "        sql = self.extract_sql_block(llm_answer)\n",
    "        try:\n",
    "            rows = self.sql_client.execute(sql)\n",
    "            return {\"sql\": sql, \"rows\": rows}\n",
    "\n",
    "        except DatabaseError as e:\n",
    "            if max_retries <= 0:\n",
    "                raise\n",
    "\n",
    "            repaired_sql = self.repair_sql(question, sql, str(e))\n",
    "            try:\n",
    "                rows = self.sql_client.execute(repaired_sql)\n",
    "                return {\n",
    "                    \"sql\": repaired_sql,\n",
    "                    \"rows\": rows,\n",
    "                    \"repaired_from\": sql,\n",
    "                    \"error\": str(e)\n",
    "                }\n",
    "            except DatabaseError:\n",
    "                return {\n",
    "                    \"sql\": repaired_sql,\n",
    "                    \"rows\": \"There was an error retrieving the data\",\n",
    "                    \"repaired_from\": sql,\n",
    "                    \"error\": str(e)\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b643a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = LLMClient(api_key=API_KEY)\n",
    "sql_client = SQLClient()\n",
    "\n",
    "data_agent = DataAgent(llm_client, sql_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6eaa9da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 15:43:11,605 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "/var/folders/9f/md89x3zj38j9zh0x6v40xsq80000gp/T/ipykernel_70708/1078916372.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql_query, conn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sql': 'WITH current_division AS (\\n    SELECT d.id\\n    FROM divisions d\\n    WHERE d.has_ended = FALSE\\n    ORDER BY d.edition_id NULLS FIRST\\n    LIMIT 1\\n),\\ntop_players AS (\\n    SELECT\\n        p.id AS player_id,\\n        p.name,\\n        p.ranking_points\\n    FROM players p\\n    ORDER BY p.ranking_points DESC\\n    LIMIT 5\\n)\\nSELECT\\n    tp.name,\\n    tp.ranking_points\\nFROM top_players tp\\nORDER BY tp.ranking_points DESC, tp.name\\n;',\n",
       " 'rows':          name  ranking_points\n",
       " 0        Fred            7089\n",
       " 1  Bernardo C            5641\n",
       " 2   Miguel SG            4675\n",
       " 3    Malafaya            3951\n",
       " 4       Dudas            3543}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_agent.run('Quem são os 5 jogadores com mais pontos de ranking?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1348e673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 17:49:03,479 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "/var/folders/9f/md89x3zj38j9zh0x6v40xsq80000gp/T/ipykernel_70708/1078916372.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql_query, conn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sql': \"-- Determine the current division (in the current edition) where a player named 'Tomás P' is placed\\nWITH current_edition AS (\\n    SELECT e.id\\n    FROM editions e\\n    JOIN divisions d ON d.edition_id = e.id\\n    WHERE d.has_ended = FALSE\\n    GROUP BY e.id\\n    HAVING bool_and(d.has_ended = FALSE)\\n    LIMIT 1\\n),\\ntom_p AS (\\n    SELECT p.id\\n    FROM players p\\n    WHERE p.name = 'Tomás P'\\n      OR p.full_name ILIKE '%Tomás P%'\\n    LIMIT 1\\n),\\nplayer_division AS (\\n    SELECT pid.division_id, d.rating\\n    FROM players_in_division pid\\n    JOIN divisions d ON d.id = pid.division_id\\n    WHERE pid.player_id = (SELECT id FROM tom_p)\\n      AND d.edition_id = (SELECT id FROM current_edition)\\n    LIMIT 1\\n)\\nSELECT\\n    CASE\\n        WHEN pd.division_id IS NULL THEN 'Não encontrado na divisão atual'\\n        ELSE CONCAT('Em ', d.name, ' (Divisão com rating ', d.rating, ')')\\n    END AS resposta\\nFROM player_division pd\\nLEFT JOIN divisions d ON d.id = pd.division_id;\",\n",
       " 'rows':                                             resposta\n",
       " 0  Em 2º Masters de Outono 2025 - 4ª Divisão (Div...}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_agent.run('Em que lugar está o Tomás P?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0913fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "\n",
    "def llm_judge(question: str, expected_df: pd.DataFrame, predicted_df: pd.DataFrame) -> str:\n",
    "\n",
    "    expected_str = expected_df.to_markdown(index=False)\n",
    "    predicted_str = predicted_df.to_markdown(index=False)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert evaluator of SQL query correctness.\n",
    "\n",
    "    Your task: Determine whether the predicted SQL query result correctly answers the user's question.\n",
    "\n",
    "    You will receive:\n",
    "    1. The question.\n",
    "    2. The ground-truth correct result (as a table).\n",
    "    3. The model-generated result (as a table).\n",
    "\n",
    "    ### IMPORTANT RULES ###\n",
    "    - The answer is CORRECT even if the columns differ, as long as the **content matches semantically**.\n",
    "    - Extra columns are allowed.\n",
    "    - Column name mismatches should be ignored.\n",
    "    - Ordering only matters if the question implies an order (e.g., \"top\", \"ordered by\").\n",
    "    - Missing irrelevant columns (e.g., ranking_position) does NOT make the answer wrong.\n",
    "    - Compare only the meaningful content needed to answer the question.\n",
    "\n",
    "    Respond with a JSON object like:\n",
    "    {{\n",
    "    \"verdict\": \"CORRECT\" or \"WRONG\",\n",
    "    \"reason\": \"short 1–2 sentence explanation\"\n",
    "    }}\n",
    "\n",
    "    ### QUESTION\n",
    "    {question}\n",
    "\n",
    "    ### GROUND TRUTH RESULT\n",
    "    {expected_str}\n",
    "\n",
    "    ### MODEL PREDICTED RESULT\n",
    "    {predicted_str}\n",
    "\n",
    "    Evaluate now.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        reasoning_effort='minimal',\n",
    "        verbosity='low'\n",
    "    )\n",
    "\n",
    "    # Attempt to parse JSON safely\n",
    "    try:\n",
    "        decision = json.loads(response.choices[0].message.content)\n",
    "        return decision\n",
    "    except:\n",
    "        return {\"verdict\": \"ERROR\", \"reason\": \"Judge output not JSON parsable\"}\n",
    "\n",
    "def evaluate_generated_sql(data_agent, questions, retries=2):\n",
    "    \"\"\"\n",
    "    For each question:\n",
    "      - runs the ground-truth SQL\n",
    "      - generates SQL via generate_sql + extract_sql_block (with retries)\n",
    "      - executes the generated SQL (with retries)\n",
    "      - uses llm_judge() to decide CORRECT/WRONG\n",
    "    Returns a DataFrame with rich metadata per question.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for q in questions:\n",
    "        user_question = q[\"question\"]\n",
    "\n",
    "        # 1) Ground truth\n",
    "        try:\n",
    "            ground_truth = data_agent.sql_client.execute(q[\"sql_query\"])\n",
    "        except Exception as e:\n",
    "            # If ground-truth fails, the eval is meaningless for this question\n",
    "            results.append({\n",
    "                \"question\": user_question,\n",
    "                \"status\": \"GROUND_TRUTH_ERROR\",\n",
    "                \"sql_query\": None,\n",
    "                \"raw_llm_output\": None,\n",
    "                \"result\": None,\n",
    "                \"ground_truth\": None,\n",
    "                \"pass\": False,\n",
    "                \"judge_reason\": \"\",\n",
    "                \"error\": f\"Ground truth failed: {e}\",\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # 2) Generate SQL via LLM\n",
    "        try:\n",
    "            llm_output = data_agent.ask_llm_client(data_agent.prompt(user_question))\n",
    "            sql_query = data_agent.extract_sql_block(llm_output)\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"question\": user_question,\n",
    "                \"status\": \"LLM_ERROR\",\n",
    "                \"sql_query\": None,\n",
    "                \"raw_llm_output\": llm_output if \"llm_output\" in locals() else None,\n",
    "                \"result\": None,\n",
    "                \"ground_truth\": ground_truth,\n",
    "                \"pass\": False,\n",
    "                \"judge_reason\": \"\",\n",
    "                \"error\": str(e),\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # 3) Execute generated SQL\n",
    "        try:\n",
    "            gen_df = data_agent.sql_client.execute(sql_query)\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"question\": user_question,\n",
    "                \"status\": \"SQL_ERROR\",\n",
    "                \"sql_query\": sql_query,\n",
    "                \"raw_llm_output\": llm_output,\n",
    "                \"result\": None,\n",
    "                \"ground_truth\": ground_truth,\n",
    "                \"pass\": False,\n",
    "                \"judge_reason\": \"\",\n",
    "                \"error\": str(e),\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # 4) Judge with LLM\n",
    "        time.sleep(1)\n",
    "        judge = llm_judge(user_question, ground_truth, gen_df)\n",
    "        verdict = judge.get(\"verdict\", \"ERROR\")\n",
    "        reason = judge.get(\"reason\", \"\")\n",
    "\n",
    "        results.append({\n",
    "            \"question\": user_question,\n",
    "            \"status\": verdict,                  # \"CORRECT\", \"WRONG\", or \"ERROR\"\n",
    "            \"sql_query\": sql_query,             # extracted SQL\n",
    "            \"raw_llm_output\": llm_output,       # full text from generate_sql\n",
    "            \"result\": gen_df,                   # model-generated dataframe\n",
    "            \"ground_truth\": ground_truth,       # reference dataframe\n",
    "            \"pass\": verdict == \"CORRECT\",\n",
    "            \"judge_reason\": reason,\n",
    "            \"error\": \"\",\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def annotate_failures(df):\n",
    "    \"\"\"\n",
    "    Adds a unified failure_reason column based on:\n",
    "      - LLM_ERROR\n",
    "      - SQL_ERROR\n",
    "      - CORRECT\n",
    "      - WRONG\n",
    "    \"\"\"\n",
    "\n",
    "    reasons = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        status = row.get(\"status\", None)\n",
    "\n",
    "        if status in (\"LLM_ERROR\", \"SQL_ERROR\"):\n",
    "            reasons.append(status)\n",
    "            continue\n",
    "\n",
    "        if status == \"CORRECT\":\n",
    "            reasons.append(\"PASS\")\n",
    "            continue\n",
    "\n",
    "        if status == \"WRONG\":\n",
    "            reasons.append(\"WRONG_RESULT\")\n",
    "            continue\n",
    "\n",
    "        # unexpected / fallback\n",
    "        reasons.append(\"UNKNOWN\")\n",
    "\n",
    "    df[\"failure_reason\"] = reasons\n",
    "    return df\n",
    "\n",
    "def inspect_failure(df, question_text):\n",
    "    \"\"\"\n",
    "    Prints a detailed inspection for a given question.\n",
    "    \"\"\"\n",
    "    row = df[df[\"question\"] == question_text].iloc[0]\n",
    "\n",
    "    print(\"\\n==========================\")\n",
    "    print(\"QUESTION:\", row[\"question\"])\n",
    "    print(\"STATUS:\", row[\"status\"])\n",
    "    print(\"REASON:\", row[\"failure_reason\"])\n",
    "    print(\"==========================\")\n",
    "\n",
    "    # For LLM extraction errors\n",
    "    if row[\"status\"] == \"LLM_ERROR\":\n",
    "        print(\"\\n❌ LLM could not generate SQL.\")\n",
    "        print(\"ERROR:\", row.get(\"error\", \"\"))\n",
    "        return\n",
    "\n",
    "    # For SQL execution errors\n",
    "    if row[\"status\"] == \"SQL_ERROR\":\n",
    "        print(\"\\n--- SQL Generated ---\")\n",
    "        print(row.get(\"sql_query\", \"(none)\"))\n",
    "        print(\"\\n❌ SQL Execution Error:\")\n",
    "        print(row.get(\"error\", \"\"))\n",
    "        return\n",
    "\n",
    "    # For CORRECT/WRONG cases\n",
    "    print(\"\\n--- SQL Generated ---\")\n",
    "    print(row.get(\"sql_query\"))\n",
    "\n",
    "    print(\"\\n--- Judge Reason ---\")\n",
    "    print(row.get(\"judge_reason\", \"\"))\n",
    "\n",
    "    print(\"\\n--- Expected Result ---\")\n",
    "    print(row.get(\"ground_truth\"))\n",
    "\n",
    "    print(\"\\n--- Actual Result ---\")\n",
    "    print(row.get(\"generated_result\"))\n",
    "\n",
    "    # Optional: try to show diff\n",
    "    try:\n",
    "        diff = row[\"ground_truth\"].compare(row[\"generated_result\"])\n",
    "        print(\"\\n--- DataFrame Differences ---\")\n",
    "        print(diff)\n",
    "    except Exception:\n",
    "        print(\"\\n--- DataFrame Differences ---\")\n",
    "        print(\"Could not compute a clean diff.\")\n",
    "        \n",
    "def summary_report(df):\n",
    "    print(\"\\n===== FAILURE SUMMARY =====\")\n",
    "    print(df[\"failure_reason\"].value_counts())\n",
    "\n",
    "    print(\"\\n===== FAILURE DETAILS =====\")\n",
    "    for reason in df[\"failure_reason\"].unique():\n",
    "        subset = df[df[\"failure_reason\"] == reason]\n",
    "        print(f\"\\n### {reason} ({len(subset)})\")\n",
    "        for q in subset[\"question\"]:\n",
    "            print(\"-\", q)\n",
    "            \n",
    "def compute_precision_score(evaluation_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    precision = (# of CORRECT queries) / (total queries evaluated)\n",
    "    \"\"\"\n",
    "    total = len(evaluation_df)\n",
    "    passed = evaluation_df[\"pass\"].sum() if \"pass\" in evaluation_df.columns else 0\n",
    "\n",
    "    precision = passed / total if total > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"total_queries\": total,\n",
    "        \"passed\": int(passed),\n",
    "        \"failed\": int(total - passed),\n",
    "        \"precision\": round(precision, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d326fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bbb1d004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9f/md89x3zj38j9zh0x6v40xsq80000gp/T/ipykernel_70708/1078916372.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql_query, conn)\n",
      "2025-11-26 15:43:26,028 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:43:29,448 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:43:30,779 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:43:33,259 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:43:34,657 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:43:37,841 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:43:40,041 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:43:42,764 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "/var/folders/9f/md89x3zj38j9zh0x6v40xsq80000gp/T/ipykernel_70708/1078916372.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql_query, conn)\n",
      "2025-11-26 15:43:45,137 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:43:47,844 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:43:49,853 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:43:52,180 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:43:54,858 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:43:57,391 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:01,154 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:03,544 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "/var/folders/9f/md89x3zj38j9zh0x6v40xsq80000gp/T/ipykernel_70708/1078916372.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql_query, conn)\n",
      "2025-11-26 15:44:07,539 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:09,910 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:13,173 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:15,254 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:18,693 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "/var/folders/9f/md89x3zj38j9zh0x6v40xsq80000gp/T/ipykernel_70708/1078916372.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql_query, conn)\n",
      "2025-11-26 15:44:21,000 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:23,745 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:29,967 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:33,962 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:37,079 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:43,915 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:47,171 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:49,406 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:52,037 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "/var/folders/9f/md89x3zj38j9zh0x6v40xsq80000gp/T/ipykernel_70708/1078916372.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql_query, conn)\n",
      "2025-11-26 15:44:55,681 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:44:58,352 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "/var/folders/9f/md89x3zj38j9zh0x6v40xsq80000gp/T/ipykernel_70708/1078916372.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql_query, conn)\n",
      "2025-11-26 15:45:02,080 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:45:05,023 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:45:09,811 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:45:12,996 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:45:16,676 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:45:19,643 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:45:24,663 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:45:27,427 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:45:36,203 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:45:38,560 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:45:41,543 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:45:45,309 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:45:47,590 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:45:50,453 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 15:45:53,213 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_queries': 25, 'passed': 10, 'failed': 15, 'precision': np.float64(0.4)}\n",
      "\n",
      "===== FAILURE SUMMARY =====\n",
      "failure_reason\n",
      "WRONG_RESULT    12\n",
      "PASS            10\n",
      "SQL_ERROR        3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "===== FAILURE DETAILS =====\n",
      "\n",
      "### PASS (10)\n",
      "- Quem são os 5 jogadores com mais pontos de ranking?\n",
      "- Quantos jogadores existem na liga?\n",
      "- Quais são os nomes das divisões atuais?\n",
      "- Quando começou a edição mais recente da liga?\n",
      "- Que campos foram usados nos jogos realizados?\n",
      "- Quantos jogos já foram jogados?\n",
      "- Quais são os jogadores da Divisão 1 e os respetivos pontos?\n",
      "- Quantas vitórias tem cada jogador da Divisão 3?\n",
      "- Mostra a classificação média (pontos) dos jogadores por divisão.\n",
      "- Quantas vezes é que o Talinho jogou a 1ª Divisão?\n",
      "\n",
      "### WRONG_RESULT (12)\n",
      "- Quem ganhou o último jogo da Divisão 2?\n",
      "- Qual é o jogador com mais jogos jogados?\n",
      "- Quantos jogos foram jogados em cada divisao?\n",
      "- Quais foram os três jogadores com mais vitórias na última edição da liga?\n",
      "- Que jogador melhorou mais a sua classificação entre duas edições consecutivas?\n",
      "- Mostra as próximas partidas (não jogadas) ordenadas por data e divisão.\n",
      "- Em que divisões joga o jogador chamado 'Pedro Pacheco'?\n",
      "- Que jogadores ganharam mais jogos jogando como equipa da casa?\n",
      "- Que jogadores jogaram mais vezes como adversários?\n",
      "- Quem ganhou mais vezes nos confrontos Dudas v Miguel SG?\n",
      "- Quem tem melhor assiduidade de sempre?\n",
      "- Quem tem melhor percentagem de vitórias de sempre?\n",
      "\n",
      "### SQL_ERROR (3)\n",
      "- Que jogadores têm mais de 100 pontos e jogaram pelo menos 5 partidas?\n",
      "- Quem é o líder atual de cada divisão?\n",
      "- Quem tem melhor percentagem de vitórias nesta edição?\n"
     ]
    }
   ],
   "source": [
    "llm_client = LLMClient(api_key=API_KEY)\n",
    "sql_client = SQLClient()\n",
    "\n",
    "data_agent = DataAgent(llm_client, sql_client)\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"queries.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    questions = json.load(f)\n",
    "\n",
    "eval_df = evaluate_generated_sql(data_agent, questions)\n",
    "eval_df = annotate_failures(eval_df)\n",
    "\n",
    "print(compute_precision_score(eval_df))\n",
    "summary_report(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c46db12",
   "metadata": {},
   "source": [
    "## Generic Answer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bc5ead68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericAnswerAgent(Agent):\n",
    "    \n",
    "    name = 'GenericAnswerAgent'\n",
    "    description = \"\"\"\n",
    "    General conversational assistant. Handles questions unrelated to padel or the league.\n",
    "    Takes a full natural-language question and returns a general answer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "\n",
    "    def run(self, question: str) -> str:\n",
    "        prompt = f\"\"\"\n",
    "        You are a helpful and friendly assistant.\n",
    "\n",
    "        Answer the user's question naturally.\n",
    "\n",
    "        User question:\n",
    "        {question}\n",
    "        \"\"\"\n",
    "        return self.llm.generate_response(\n",
    "            prompt=prompt,\n",
    "            reasoning_effort = 'minimal',\n",
    "            verbosity = 'low'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "39272ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 22:33:52,662 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi there! How can I help you today?'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_client = LLMClient(api_key=API_KEY)\n",
    "generic_answer_agent = GenericAnswerAgent(llm_client)\n",
    "generic_answer_agent.run('Hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ef7aab",
   "metadata": {},
   "source": [
    "## Padel League Answer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1d8055e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadelLeagueAnswerAgent(Agent):\n",
    "    \n",
    "    name = 'PadelLeagueAnswerAgent'\n",
    "    description = \"\"\"\n",
    "    Padel League conversational assistant. Handles questions related to the padel league.\n",
    "    Takes a full natural-language question, calls the SQL agent to generate a SQL query to fetch information from the DB.\n",
    "    \n",
    "    Has access to a SQL agent that retrieves structured data from the SQL database. \n",
    "    Takes a list of fully-formed natural-language questions about the padel league, \n",
    "    divisions, matches, schedules, rankings, or players.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm, data_agent):\n",
    "        self.llm = llm\n",
    "        self.data_agent = data_agent\n",
    "\n",
    "    def run(self, questions: str) -> str:\n",
    "        db_result = [\n",
    "            {\"question\": question, \"db_result\": self.data_agent.run(question)}\n",
    "            for question in questions\n",
    "        ]\n",
    "\n",
    "        db_rows_str = \"\\n\".join(\n",
    "            f\"Question: {item['question']}\\nRows: {item['db_result'].get('rows', [])}\\n\"\n",
    "            for item in db_result\n",
    "        )\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are the Padel League Assistant.\n",
    "\n",
    "        Here is data retrieved from the database:\n",
    "\n",
    "        {db_rows_str}\n",
    "\n",
    "        Craft a precise, correct, friendly answer based on the data.\n",
    "        If an answer cannot be determined from the available rows, explain why.\n",
    "        Always answer in European Portuguese. You should be funny and sarcastic.\n",
    "        \n",
    "        If the information is missing please tell the user that you coulnd't retrieve information from the db, \n",
    "        ask him to rephrase the question. Only do this if the information is missing.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.llm.generate_response(\n",
    "            prompt=prompt,\n",
    "            reasoning_effort = 'minimal',\n",
    "            verbosity = 'low'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a5a1d59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 14:13:25,728 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "/var/folders/9f/md89x3zj38j9zh0x6v40xsq80000gp/T/ipykernel_70708/1078916372.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql_query, conn)\n",
      "2025-12-02 14:13:27,700 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Aqui vai, direto ao assunto: os 5 jogadores com mais pontos de ranking são, segundo os dados disponíveis:\\n\\n1) Zema — 113 pontos\\n2) Martinho — 82 pontos\\n3) Cou — 49 pontos\\n4) Bucas — 33 pontos\\n5) Cameira — 26 pontos\\n\\nSe quiseres verificar mais detalhes ou se a ordem mudar com novas entradas, diz-me e atualizo. E sim, eu sei: podia haver mais contexto, mas estes são os dados que tenho. Se precisares de outra coisa, renova a query ou pergunta outra coisa!'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_client = LLMClient(api_key=API_KEY)\n",
    "sql_client = SQLClient()\n",
    "\n",
    "data_agent = DataAgent(llm_client, sql_client)\n",
    "\n",
    "question = 'Quem são os 5 jogadores com mais pontos de ranking?'\n",
    "\n",
    "padelleague_answer_agent = PadelLeagueAnswerAgent(llm_client, data_agent)\n",
    "padelleague_answer_agent.run([question])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264ac374",
   "metadata": {},
   "source": [
    "## Orchestrator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "\n",
    "class OrchestratorAgent:\n",
    "    def __init__(self, llm, agents):\n",
    "        self.llm = llm\n",
    "        self.agents = agents\n",
    "        self.agents_description = [{\"name\": agent.name, \"description\": agent.description} for agent in agents]\n",
    "        self.conversation = LLMConversation(\"You are a helpful assistant.\")\n",
    "        self.agents_dict = {agent.name: agent for agent in agents}\n",
    "\n",
    "    def choose_agents(self, user_message):\n",
    "        prompt = f\"\"\"\n",
    "        You are the Orchestrator Agent in a multi-agent system.\n",
    "\n",
    "        Your job is to:\n",
    "        1. Understand the user's message IN CONTEXT of the conversation.\n",
    "        2. Rewrite the message into one or more explicit questions.\n",
    "        3. Decide which agent should answer each question.\n",
    "        4. Output ONLY valid JSON.\n",
    "\n",
    "        Here are the available agents:\n",
    "        {self.agents_description}\n",
    "\n",
    "        Rules:\n",
    "        - If the question is NOT related to padel or the padel league → assign to GenericAnswerAgent.\n",
    "        - If the question IS related to padel league, divisions, players, standings, matches → assign to PadelLeagueAnswerAgent.\n",
    "        - If the user asks multiple questions, split them into separate tasks, each understandable for a standalone agent.\n",
    "        - If the user refers to previous context (e.g. \"and division 2?\"), rewrite into a full, explicit question.\n",
    "        - Keep the questions as simple as possible. Don't add information you don't see somewhere in the conversation.\n",
    "        - ALWAYS return a JSON object with a top-level field \"agent\", which is a list of calls.\n",
    "\n",
    "        Example output format:\n",
    "        {{\n",
    "        \"agent\": [\n",
    "            {{\n",
    "            \"name\": \"PadelLeagueAnswerAgent\",\n",
    "            \"question\": [\n",
    "                \"What are the points for division 2 in the 2024 season?\"\n",
    "                ]\n",
    "            }}\n",
    "        ]\n",
    "        }}\n",
    "        \n",
    "        or \n",
    "        \n",
    "        {{\n",
    "        \"agent\": [\n",
    "            {{\n",
    "            \"name\": \"GenericAnswerAgent\",\n",
    "            \"question\": \"Explain why padel is so popular.\"\n",
    "            }}\n",
    "        ]\n",
    "        }}\n",
    "\n",
    "        User message:\n",
    "        {user_message}\n",
    "\n",
    "        Respond with JSON only.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        new_conversation = copy.deepcopy(self.conversation)\n",
    "        new_conversation.add_message(\"user\", prompt)\n",
    "        \n",
    "        raw = self.llm.generate_response_for_conversation(\n",
    "            conversation=new_conversation,\n",
    "            reasoning_effort = 'minimal',\n",
    "            verbosity = 'low'\n",
    "        )\n",
    "        return json.loads(raw)\n",
    "    \n",
    "    def run(self, user_message):\n",
    "        tasks = self.choose_agents(user_message)\n",
    "        agent_name = tasks['agent'][0]['name']\n",
    "        question = tasks['agent'][0]['question']\n",
    "        agent = self.agents_dict[agent_name]\n",
    "        answer = agent.run(question)\n",
    "        self.conversation.add_message(\"user\", user_message)\n",
    "        self.conversation.add_message(\"assistant\", answer)\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b119a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = LLMClient(api_key=API_KEY)\n",
    "sql_client = SQLClient()\n",
    "\n",
    "data_agent = DataAgent(llm_client, sql_client)\n",
    "\n",
    "generic_answer_agent = GenericAnswerAgent(llm_client)\n",
    "padelleague_answer_agent = PadelLeagueAnswerAgent(llm_client, data_agent)\n",
    "\n",
    "orchestrator_agent = OrchestratorAgent(llm_client, [generic_answer_agent, padelleague_answer_agent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "dfc026ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LLMMessage(role='system', content='You are a helpful assistant.', max_tokens=1024)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orchestrator_agent.conversation.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "407531c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 14:18:38,680 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "------------------------\n",
      "['Quem são os 5 jogadores com mais pontos de ranking no ranking da liga?', 'Quem são os 5 jogadores com menos pontos de ranking no ranking da liga?']\n",
      "------------------------\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 14:18:41,297 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "/var/folders/9f/md89x3zj38j9zh0x6v40xsq80000gp/T/ipykernel_70708/1078916372.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql_query, conn)\n",
      "2025-12-02 14:18:43,551 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-12-02 14:18:46,539 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Claro! Vamos aos dados que me deram.\\n\\n- 5 jogadores com mais pontos de ranking: Bernardo C, Malafaya, Carlo, Pancho, Dinis.\\n\\n- 5 jogadores com menos pontos de ranking: Chico Castro, Falcão, Falcão, Luís Ferreira, Miguel C.\\n\\nSe precisares de uma lista sem repetições para os de menor, o dataset mostra Falcão duas vezes com 0 pontos, o que pode estar a duplicar registos. Se considerarmos apenas nomes únicos, os menos pontos são: Chico Castro, Falcão, Luís Ferreira, Miguel C. (com 0 pontos). Mas, como o ficheiro mostra duplicado de Falcão, mantemos como está: Chico Castro, Falcão, Falcão, Luís Ferreira, Miguel C.\\n\\n Precisas que eu corrija para apenas jogadores únicos ou confirmar se as duplicatas devem contar? Vou ajustar se me deres permissão. E sim, o Bruno Volta a pedir: sou o teu Padel League Assistant, com o humorzinho sarcástico a marcar presença.'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'Quem são os 5 jogadores com mais pontos de ranking? E os 5 com menos?'\n",
    "\n",
    "orchestrator_agent.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ae7ff6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 14:18:47,995 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "------------------------\n",
      "['Quem é o jogador com mais empates no ranking da Liga de Padel?']\n",
      "------------------------\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 14:18:50,827 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "/var/folders/9f/md89x3zj38j9zh0x6v40xsq80000gp/T/ipykernel_70708/1078916372.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(sql_query, conn)\n",
      "2025-12-02 14:18:52,581 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Pelo que aparece nos dados disponíveis, o jogador com mais empates é Bernardo C, com 0.0 empates. \\n\\nSe procuras outra pessoa com mais empates ou se há mais linhas no banco de dados, dá-me o conjunto completo e eu digo-te já quem lidera. Não mefaças brincar com o fecho da rede sem dados!'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orchestrator_agent.conversation.add_message(\"user\", \"Quem é o jogador com mais empates?\")\n",
    "orchestrator_agent.conversation.add_message(\"assistant\", \"Não consegui encontrar essa informação.\")\n",
    "\n",
    "question = \"Tenta outra vez pf\"\n",
    "orchestrator_agent.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be5e13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padel-league-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
